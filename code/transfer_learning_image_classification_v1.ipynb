{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab-related code"
      ],
      "metadata": {
        "id": "YqS1kUhA3s74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ai_image_classification_cifar/code')\n",
        "%cd /content/drive/My\\ Drive/ai_image_classification_cifar/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXnwoQfxYVHI",
        "outputId": "edb6b886-81f1-4672-bf52-34af47b0d6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ai_image_classification_cifar/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up environment"
      ],
      "metadata": {
        "id": "GMElIw-k4H0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary dependencies\n",
        "!bash install-dependencies.sh\n",
        "\n",
        "#Install packages\n",
        "from required_packages import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tbnzbxKc4Bg",
        "outputId": "73092f44-b193-4c4a-989a-d8e4e173175c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pandas==2.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.1.4)\n",
            "Collecting tensorflow==2.17.0 (from -r requirements.txt (line 6))\n",
            "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting keras==3.4.1 (from -r requirements.txt (line 7))\n",
            "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.3.2)\n",
            "Collecting Pillow==9.4.0 (from -r requirements.txt (line 13))\n",
            "  Downloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: fastdownload==0.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.0.7)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (3.7.1)\n",
            "Requirement already satisfied: seaborn==0.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.13.1)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow==2.17.0->-r requirements.txt (line 6))\n",
            "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (1.65.4)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow==2.17.0->-r requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 6)) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1->-r requirements.txt (line 7)) (13.7.1)\n",
            "Collecting namex (from keras==3.4.1->-r requirements.txt (line 7))\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras==3.4.1->-r requirements.txt (line 7))\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m914.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.10/dist-packages (from fastdownload==0.0.7->-r requirements.txt (line 16)) (1.0.3)\n",
            "Requirement already satisfied: fastcore>=1.3.26 in /usr/local/lib/python3.10/dist-packages (from fastdownload==0.0.7->-r requirements.txt (line 16)) (1.5.55)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (3.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0->-r requirements.txt (line 6)) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 6)) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 6)) (2.1.5)\n",
            "Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m186.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, Pillow, optree, ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 10.4.0\n",
            "    Uninstalling pillow-10.4.0:\n",
            "      Successfully uninstalled pillow-10.4.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 keras-3.4.1 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 tensorboard-2.17.1 tensorflow-2.17.0\n",
            "Installed packages:\n",
            "Package                      Version\n",
            "---------------------------- -----------------------\n",
            "absl-py                      1.4.0\n",
            "accelerate                   0.32.1\n",
            "altair                       4.2.2\n",
            "annotated-types              0.7.0\n",
            "anyio                        3.7.1\n",
            "argon2-cffi                  23.1.0\n",
            "argon2-cffi-bindings         21.2.0\n",
            "array_record                 0.5.1\n",
            "astunparse                   1.6.3\n",
            "attrs                        24.2.0\n",
            "audioread                    3.0.1\n",
            "backcall                     0.2.0\n",
            "beautifulsoup4               4.12.3\n",
            "bleach                       6.1.0\n",
            "blinker                      1.4\n",
            "blis                         0.7.11\n",
            "build                        1.2.1\n",
            "cachetools                   5.4.0\n",
            "catalogue                    2.0.10\n",
            "certifi                      2024.7.4\n",
            "cffi                         1.17.0\n",
            "charset-normalizer           3.3.2\n",
            "chex                         0.1.86\n",
            "click                        8.1.7\n",
            "cloud-tpu-client             0.10\n",
            "cloudpathlib                 0.18.1\n",
            "cloudpickle                  3.0.0\n",
            "confection                   0.1.5\n",
            "contourpy                    1.2.1\n",
            "cryptography                 3.4.8\n",
            "cycler                       0.12.1\n",
            "cymem                        2.0.8\n",
            "dbus-python                  1.2.18\n",
            "debugpy                      1.6.6\n",
            "decorator                    5.1.1\n",
            "defusedxml                   0.7.1\n",
            "distrax                      0.1.5\n",
            "distro                       1.7.0\n",
            "dm-tree                      0.1.8\n",
            "docstring_parser             0.16\n",
            "dopamine_rl                  4.0.9\n",
            "en-core-web-sm               3.7.1\n",
            "entrypoints                  0.4\n",
            "etils                        1.7.0\n",
            "exceptiongroup               1.2.2\n",
            "fastai                       2.7.16\n",
            "fastcore                     1.5.55\n",
            "fastdownload                 0.0.7\n",
            "fastjsonschema               2.20.0\n",
            "fastprogress                 1.0.3\n",
            "filelock                     3.15.4\n",
            "flatbuffers                  24.3.25\n",
            "flax                         0.8.4\n",
            "fonttools                    4.53.1\n",
            "fsspec                       2024.6.1\n",
            "funcsigs                     1.0.2\n",
            "gast                         0.6.0\n",
            "GDAL                         3.6.4\n",
            "gdown                        5.1.0\n",
            "gensim                       4.3.3\n",
            "gin-config                   0.5.0\n",
            "google                       2.0.3\n",
            "google-api-core              1.34.1\n",
            "google-api-python-client     1.8.0\n",
            "google-auth                  2.27.0\n",
            "google-auth-httplib2         0.2.0\n",
            "google-auth-oauthlib         1.2.1\n",
            "google-cloud-core            2.4.1\n",
            "google-cloud-storage         2.8.0\n",
            "google-colab                 1.0.0\n",
            "google-crc32c                1.5.0\n",
            "google-pasta                 0.2.0\n",
            "google-resumable-media       2.7.2\n",
            "googleapis-common-protos     1.63.2\n",
            "grpcio                       1.65.4\n",
            "gspread                      6.0.2\n",
            "gspread-dataframe            3.3.1\n",
            "gym                          0.25.2\n",
            "gym-notices                  0.0.8\n",
            "h5py                         3.11.0\n",
            "httplib2                     0.22.0\n",
            "huggingface-hub              0.23.5\n",
            "idna                         3.7\n",
            "imageio                      2.34.2\n",
            "immutabledict                4.2.0\n",
            "importlib-metadata           4.6.4\n",
            "importlib_resources          6.4.0\n",
            "iniconfig                    2.0.0\n",
            "ipykernel                    5.5.6\n",
            "ipyparallel                  8.8.0\n",
            "ipython                      7.34.0\n",
            "ipython-genutils             0.2.0\n",
            "ipywidgets                   7.7.1\n",
            "jax                          0.4.26\n",
            "jaxlib                       0.4.26\n",
            "jeepney                      0.7.1\n",
            "Jinja2                       3.1.4\n",
            "joblib                       1.4.2\n",
            "jsonschema                   4.23.0\n",
            "jsonschema-specifications    2023.12.1\n",
            "jupyter-client               6.1.12\n",
            "jupyter-console              6.1.0\n",
            "jupyter_core                 5.7.2\n",
            "jupyter-server               1.24.0\n",
            "jupyterlab_pygments          0.3.0\n",
            "jupyterlab_widgets           3.0.11\n",
            "kaggle                       1.6.17\n",
            "kagglehub                    0.2.9\n",
            "keras                        3.4.1\n",
            "keyring                      23.5.0\n",
            "kiwisolver                   1.4.5\n",
            "langcodes                    3.4.0\n",
            "language_data                1.2.0\n",
            "launchpadlib                 1.10.16\n",
            "lazr.restfulclient           0.14.4\n",
            "lazr.uri                     1.0.6\n",
            "lazy_loader                  0.4\n",
            "libclang                     18.1.1\n",
            "librosa                      0.10.2.post1\n",
            "libtpu-nightly               0.1.dev20240403+default\n",
            "llvmlite                     0.43.0\n",
            "marisa-trie                  1.2.0\n",
            "Markdown                     3.6\n",
            "markdown-it-py               3.0.0\n",
            "MarkupSafe                   2.1.5\n",
            "matplotlib                   3.7.1\n",
            "matplotlib-inline            0.1.7\n",
            "mdurl                        0.1.2\n",
            "mistune                      3.0.2\n",
            "ml-dtypes                    0.4.0\n",
            "more-itertools               8.10.0\n",
            "mpmath                       1.3.0\n",
            "msgpack                      1.0.8\n",
            "murmurhash                   1.0.10\n",
            "namex                        0.0.8\n",
            "nbclassic                    1.1.0\n",
            "nbclient                     0.10.0\n",
            "nbconvert                    7.16.4\n",
            "nbformat                     5.10.4\n",
            "nest-asyncio                 1.6.0\n",
            "networkx                     3.3\n",
            "nltk                         3.8.1\n",
            "notebook                     6.5.5\n",
            "notebook_shim                0.2.4\n",
            "numba                        0.60.0\n",
            "numpy                        1.26.4\n",
            "oauth2client                 4.1.3\n",
            "oauthlib                     3.2.2\n",
            "opencv-python                4.10.0.84\n",
            "opt-einsum                   3.3.0\n",
            "optax                        0.1.9\n",
            "optree                       0.12.1\n",
            "orbax-checkpoint             0.4.4\n",
            "packaging                    24.1\n",
            "pandas                       2.1.4\n",
            "pandas-stubs                 2.1.4.231227\n",
            "pandocfilters                1.5.1\n",
            "parso                        0.8.4\n",
            "pexpect                      4.9.0\n",
            "pickleshare                  0.7.5\n",
            "Pillow                       9.4.0\n",
            "pip                          24.1.2\n",
            "pip-tools                    7.4.1\n",
            "platformdirs                 4.2.2\n",
            "plotly                       5.15.0\n",
            "pluggy                       1.5.0\n",
            "pooch                        1.8.2\n",
            "portpicker                   1.5.2\n",
            "preshed                      3.0.9\n",
            "prometheus_client            0.20.0\n",
            "promise                      2.3\n",
            "prompt_toolkit               3.0.47\n",
            "protobuf                     3.20.3\n",
            "psutil                       5.9.5\n",
            "ptyprocess                   0.7.0\n",
            "pyarrow                      17.0.0\n",
            "pyasn1                       0.6.0\n",
            "pyasn1_modules               0.4.0\n",
            "pycparser                    2.22\n",
            "pydantic                     2.8.2\n",
            "pydantic_core                2.20.1\n",
            "pygame                       2.6.0\n",
            "Pygments                     2.18.0\n",
            "PyGObject                    3.42.1\n",
            "PyJWT                        2.3.0\n",
            "pyparsing                    3.1.2\n",
            "pyproject_hooks              1.1.0\n",
            "PySocks                      1.7.1\n",
            "pytest                       7.4.4\n",
            "python-apt                   2.4.0\n",
            "python-dateutil              2.9.0.post0\n",
            "python-slugify               8.0.4\n",
            "pytz                         2024.1\n",
            "PyYAML                       6.0.2\n",
            "pyzmq                        24.0.1\n",
            "referencing                  0.35.1\n",
            "regex                        2024.7.24\n",
            "requests                     2.32.3\n",
            "requests-oauthlib            2.0.0\n",
            "requirements-parser          0.9.0\n",
            "rich                         13.7.1\n",
            "rpds-py                      0.20.0\n",
            "rpy2                         3.4.2\n",
            "rsa                          4.9\n",
            "safetensors                  0.4.4\n",
            "scikit-image                 0.23.2\n",
            "scikit-learn                 1.3.2\n",
            "scipy                        1.13.1\n",
            "seaborn                      0.13.1\n",
            "SecretStorage                3.3.1\n",
            "Send2Trash                   1.8.3\n",
            "sentencepiece                0.1.99\n",
            "setuptools                   71.0.4\n",
            "shellingham                  1.5.4\n",
            "simple_parsing               0.1.5\n",
            "six                          1.16.0\n",
            "sklearn-pandas               2.2.0\n",
            "smart-open                   7.0.4\n",
            "sniffio                      1.3.1\n",
            "soundfile                    0.12.1\n",
            "soupsieve                    2.5\n",
            "soxr                         0.4.0\n",
            "spacy                        3.7.5\n",
            "spacy-legacy                 3.0.12\n",
            "spacy-loggers                1.0.5\n",
            "srsly                        2.4.8\n",
            "StrEnum                      0.4.15\n",
            "sympy                        1.13.1\n",
            "tenacity                     9.0.0\n",
            "tensorboard                  2.17.1\n",
            "tensorboard-data-server      0.7.2\n",
            "tensorflow                   2.17.0\n",
            "tensorflow-datasets          4.9.6\n",
            "tensorflow-estimator         2.15.0\n",
            "tensorflow-hub               0.16.1\n",
            "tensorflow-io-gcs-filesystem 0.37.1\n",
            "tensorflow-metadata          1.15.0\n",
            "tensorflow-probability       0.24.0\n",
            "tensorflow-text              2.15.0\n",
            "tensorstore                  0.1.45\n",
            "termcolor                    2.4.0\n",
            "terminado                    0.18.1\n",
            "text-unidecode               1.3\n",
            "tf_keras                     2.15.1\n",
            "tf-slim                      1.1.0\n",
            "thinc                        8.2.5\n",
            "threadpoolctl                3.5.0\n",
            "tifffile                     2024.7.24\n",
            "tinycss2                     1.3.0\n",
            "tokenizers                   0.19.1\n",
            "toml                         0.10.2\n",
            "tomli                        2.0.1\n",
            "toolz                        0.12.1\n",
            "torch                        2.3.0+cpu\n",
            "torch-xla                    2.3.0+libtpu\n",
            "torchaudio                   2.3.0+cpu\n",
            "torchtext                    0.18.0\n",
            "torchvision                  0.18.0+cpu\n",
            "tornado                      6.3.3\n",
            "tpu-info                     0.0.1\n",
            "tqdm                         4.66.5\n",
            "traitlets                    5.7.1\n",
            "transformers                 4.42.4\n",
            "trax                         1.4.1\n",
            "typer                        0.12.3\n",
            "types-pytz                   2024.1.0.20240417\n",
            "types-setuptools             71.1.0.20240813\n",
            "typing_extensions            4.12.2\n",
            "tzdata                       2024.1\n",
            "tzlocal                      5.2\n",
            "uritemplate                  3.0.1\n",
            "urllib3                      2.0.7\n",
            "vega-datasets                0.9.0\n",
            "wadllib                      1.3.6\n",
            "wasabi                       1.1.3\n",
            "wcwidth                      0.2.13\n",
            "weasel                       0.4.1\n",
            "webencodings                 0.5.1\n",
            "websocket-client             1.8.0\n",
            "Werkzeug                     3.0.3\n",
            "wheel                        0.44.0\n",
            "widgetsnbextension           3.6.8\n",
            "wrapt                        1.14.1\n",
            "zipp                         3.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source images"
      ],
      "metadata": {
        "id": "wZu0tCVozz44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this code when sourcing images from Kaggle account. However, do not run this when images are already sourced.\n",
        "class Images:\n",
        "    '''\n",
        "    A class to source images.\n",
        "    '''\n",
        "    def __init__(self, num_images):\n",
        "        self.num_images = num_images\n",
        "        self.orig_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images'\n",
        "        self.dest_dir = '/kaggle/working/cifake'\n",
        "\n",
        "    def copy_images(self):\n",
        "        categories = ['FAKE', 'REAL']\n",
        "        dataset_type = ['train', 'test']\n",
        "\n",
        "        #Copy train & test images\n",
        "        for i in dataset_type:\n",
        "            for j in categories:\n",
        "                orig_dir = os.path.join(self.orig_dir, i, j)\n",
        "                dest_dir = os.path.join(self.dest_dir, i, j)\n",
        "                functions.source_images(orig_dir = orig_dir, dest_dir = dest_dir, num_images = self.num_images, seed = 23)\n",
        "        #Copy validation images\n",
        "        for j in categories:\n",
        "            train_dir= os.path.join(self.dest_dir, 'train', j)\n",
        "            validation_dir = '/kaggle/working/cifake/validation'\n",
        "\n",
        "            all_files = os.listdir(train_dir)\n",
        "            random.seed(23)\n",
        "            selected_files = random.sample(all_files, 100)\n",
        "\n",
        "            for file in selected_files:\n",
        "                train_file_path = os.path.join(train_dir, file)\n",
        "                validation_file_path = os.path.join(validation_dir, j, file)\n",
        "                os.makedirs(validation_file_path, exist_ok=True)\n",
        "                shutil.copy(train_file_path, validation_file_path)\n",
        "\n",
        "                os.remove(train_file_path)"
      ],
      "metadata": {
        "id": "seiCDGM58UGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess images"
      ],
      "metadata": {
        "id": "e4OYEhBQ488-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    def __init__(self, **mdict):\n",
        "        self.mdict = mdict\n",
        "\n",
        "    def create_generators(self):\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale = self.mdict['generators']['rescale'],\n",
        "            rotation_range = self.mdict['generators']['rotation_range'],\n",
        "            width_shift_range = self.mdict['generators']['width_shift_range'],\n",
        "            height_shift_range = self.mdict['generators']['height_shift_range'],\n",
        "            shear_range = self.mdict['generators']['shear_range'],\n",
        "            zoom_range = self.mdict['generators']['zoom_range'],\n",
        "            fill_mode = self.mdict['generators']['fill_mode'])\n",
        "\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            self.mdict['info']['train_dir'],\n",
        "            target_size = (224, 224),\n",
        "            batch_size = 32,\n",
        "            classes = self.mdict['info']['classes'])\n",
        "\n",
        "        validation_generator = ImageDataGenerator().flow_from_directory(\n",
        "            self.mdict['info']['validation_dir'],\n",
        "            target_size = (224, 224),\n",
        "            batch_size = 32,\n",
        "            classes = self.mdict['info']['classes'])\n",
        "\n",
        "        test_generator = ImageDataGenerator().flow_from_directory(\n",
        "            self.mdict['info']['test_dir'],\n",
        "            target_size = (224, 224),\n",
        "            batch_size = 32,\n",
        "            classes = self.mdict['info']['classes'],\n",
        "            shuffle = False)\n",
        "\n",
        "        return train_generator, validation_generator, test_generator"
      ],
      "metadata": {
        "id": "xqutCs4448mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load YAML file and create training, validation, and test datasets"
      ],
      "metadata": {
        "id": "vBehcWNydZU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_file = '../input/base_tf_dict.yaml'\n",
        "\n",
        "with open(yaml_file, 'r') as file:\n",
        "    df_dict = yaml.safe_load(file)\n",
        "\n",
        "generator = Preprocess(**df_dict)\n",
        "train_generator, validation_generator, test_generator = generator.create_generators()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHwK30Lx8dn6",
        "outputId": "eae590b8-aa2d-4935-a5f5-ef77a4575e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 735 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create base model from pre-trained MobileNet V2 Model (Google)"
      ],
      "metadata": {
        "id": "Z1oBjwrJE5-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "  # Load pre-trained model without the top classification layer (dense layers)\n",
        "  # Load pretrained weights from imagenet\n",
        "\n",
        "IMG_SIZE = df_dict['preprocess']['resize']\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "tf_model = tf.keras.applications.MobileNetV2(input_shape= IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Feature extraction: freeze convolutional base and add classifier\n",
        "tf_model.trainable = False\n",
        "\n",
        "#Identify feature batch\n",
        "image_batch, label_batch = next(iter(train_generator))\n",
        "feature_batch = tf_model(image_batch)\n",
        "print(feature_batch.shape) #7 x 7 x 1280 block of features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Tj1g-sPaB7ee",
        "outputId": "fefe2119-1f49-4c2c-fff9-91784f94d7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_dict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-176c1781ce80>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Load pretrained weights from imagenet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mIMG_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocess'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mIMG_SHAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMG_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m tf_model = tf.keras.applications.MobileNetV2(input_shape= IMG_SHAPE,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add classification head; use GlobalAveragePooling2D to convert block of features to a single 1280 element vector per image\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape) #(32, 1280)\n",
        "\n",
        "# Apply Dense layer to convert features into a single prediction per image: positive #s predict class 1, negative #s predict class 0\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape) #(32, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbxg2hJ2DgSg",
        "outputId": "104bc2ea-d75b-4c1f-fafa-cb5efddcb091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1280)\n",
            "(32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "inputs = tf.keras.Input(shape=(df_dict['preprocess']['resize']))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x) #Adds GlobalAveragePooling2D layer\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x) #Adds Dense layer: sigmoid\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "nGhZrLs1D8e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=df_dict['transfer_learning']['learning_rate']),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
      ],
      "metadata": {
        "id": "NGZGq2cUEaf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=df_dict['transfer_learning']['initial_epochs'],\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4K3nJDAFrZy",
        "outputId": "e61324e6-ed5e-4def-e8a7-fa96f34934f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 184s 8s/step - loss: 0.7190 - accuracy: 0.5000 - val_loss: 0.7302 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 17s 691ms/step - loss: 0.7131 - accuracy: 0.5000 - val_loss: 0.7288 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 17s 683ms/step - loss: 0.7083 - accuracy: 0.5000 - val_loss: 0.7316 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 17s 674ms/step - loss: 0.7050 - accuracy: 0.5000 - val_loss: 0.7276 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 17s 681ms/step - loss: 0.7032 - accuracy: 0.5000 - val_loss: 0.7281 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 17s 687ms/step - loss: 0.7014 - accuracy: 0.5000 - val_loss: 0.7247 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 17s 683ms/step - loss: 0.6989 - accuracy: 0.5000 - val_loss: 0.7359 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 17s 683ms/step - loss: 0.6980 - accuracy: 0.5000 - val_loss: 0.7284 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 673ms/step - loss: 0.6972 - accuracy: 0.5000 - val_loss: 0.7285 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 660ms/step - loss: 0.6967 - accuracy: 0.5000 - val_loss: 0.7299 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning"
      ],
      "metadata": {
        "id": "SndnmtpdUKgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights to be tuned from generic feature maps to features associated with dataset"
      ],
      "metadata": {
        "id": "_gsSXDDWVCPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unfreeze the base_model\n",
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "RX1CWsxNVcD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndeQJMhdViPA",
        "outputId": "fd3d4512-1c18-4480-e094-3b03c922a9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
      ],
      "metadata": {
        "id": "ws271UN4VoR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chY7JOEPVx1G",
        "outputId": "9b3508e0-5124-4414-ee9c-7bd0d606315d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, None, None, None   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambd  (None, 224, 224, 3)       0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLamb  (None, 224, 224, 3)       0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 1280)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2259265 (8.62 MB)\n",
            "Trainable params: 1862721 (7.11 MB)\n",
            "Non-trainable params: 396544 (1.51 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_generator,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=len(history.epoch),\n",
        "                         validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or_oJkMfV26Q",
        "outputId": "44242752-7aa2-47bc-ae69-e367a5677b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "25/25 [==============================] - 23s 743ms/step - loss: 0.7132 - accuracy: 0.5000 - val_loss: 0.7383 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 18s 714ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.7356 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 18s 720ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.7341 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 18s 726ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7327 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 18s 726ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7313 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 18s 719ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7306 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 18s 712ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 18s 722ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7296 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 18s 709ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7294 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 18s 711ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7292 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archived Code"
      ],
      "metadata": {
        "id": "efyFubKL5Y5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Display images\n",
        "# #Use data augmentation\n",
        "# data_augmentation = keras.Sequential(\n",
        "#     [tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "#      tf.keras.layers.RandomRotation(0.1),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# #Get batch of images from train generator\n",
        "# image_batch, _ = next(train_generator)\n",
        "# first_image = image_batch[1]\n",
        "\n",
        "# # Plotting augmented images\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(9):\n",
        "#     ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "#     # Apply data augmentation\n",
        "#     augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "\n",
        "#     # Remove the batch dimension and convert the augmented image to a valid range for display\n",
        "#     augmented_image = augmented_image[0].numpy()\n",
        "\n",
        "#     # Rescale augmented_image to the range [0, 1] for display\n",
        "#     augmented_image = (augmented_image + 1) / 2.0\n",
        "\n",
        "#     # Display the augmented image\n",
        "#     plt.imshow(augmented_image)\n",
        "#     plt.axis('off')"
      ],
      "metadata": {
        "id": "6cxlYkmM5dpx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}